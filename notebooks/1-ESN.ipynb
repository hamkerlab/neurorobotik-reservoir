{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla echo-state network\n",
    "\n",
    "The goal of this exercise is to get some intuition about the functioning of echo-state networks.\n",
    "\n",
    "Uncomment this line to install ANNarchy if you haven't already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ANNarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's start by importing numpy, matplotlib and ANNarchy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ANNarchy as ann"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent ESN neurons are defined by a variable $x$ following this ODE:\n",
    "\n",
    "$$\n",
    "    \\tau \\, \\dfrac{d x}{dt} + x = \\sum_\\text{inputs} w_i \\, r_i + \\sum_\\text{recurrent} w_i \\, r_i\n",
    "$$\n",
    "\n",
    "where $\\tau$ is a time constant. They integrate two sorts of inputs, coming from input neurons and the other recurrent neurons.\n",
    "\n",
    "The firing rate $r$ of a neuron applies the `tanh` function on $x$:\n",
    "\n",
    "$$\n",
    "    r = \\tanh{x}\n",
    "$$\n",
    "\n",
    "The following cell defines such a neuron in ANNarchy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ESN_Neuron = ann.Neuron(\n",
    "    parameters = \"\"\"\n",
    "        tau = 30.0     : population   # Time constant\n",
    "        g = 1.0        : population   # Scaling\n",
    "    \"\"\",\n",
    "    equations=\"\"\"\n",
    "        tau * dx/dt + x = sum(in) + g * sum(exc)\n",
    "        r = tanh(x)\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ESN is typically composed of an input population, the reservoir with random recurrent connections and a readout population linearly reading the reservoir's activity:\n",
    "\n",
    "$$\n",
    "    \\mathbf{z} = W^\\text{out} \\times \\mathbf{r}\n",
    "$$\n",
    "\n",
    "The following class defines an input population with a single neuron and a reservoir of `N` neurons. The readout population will be implemented externally.\n",
    "\n",
    "The weights between the input and recurrent populations are randomly drawn from $\\mathcal{N}(0, 1)$. The recurrent weights are drawn from $\\mathcal{N}(0, \\dfrac{1}{\\sqrt{N}})$.\n",
    "\n",
    "The scaling factor $g$ is integrated in the neuron definition, what allows to vary it easily without redrawing the random weights.\n",
    "\n",
    "The `trial()` method allows to simulate the ESN for a single trial. After a reset period of 100 ms, an impulse is set in the input population for 100 ms. The ESN relayes for the rest of the trial (duration - 200 ms). The monitor records the firing rate `r` in the recurrent population and returns it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESN:\n",
    "    \"\"\"\n",
    "    Echo-state network implemented in ANNarchy.\n",
    "    \"\"\"\n",
    "    def __init__(self, N:int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            N : number of neurons in the reservoir\n",
    "        \"\"\"\n",
    "        self.N = N\n",
    "\n",
    "        # Clear ANNarchy to allow multiple instances.\n",
    "        ann.clear()\n",
    "\n",
    "        # Input population\n",
    "        self.inp = ann.Population(1, ann.Neuron(parameters=\"r=0.0\"))\n",
    "\n",
    "        # Recurrent population\n",
    "        self.reservoir = ann.Population(N, ESN_Neuron)\n",
    "\n",
    "        # Input weights\n",
    "        self.Wi = ann.Projection(self.inp, self.reservoir, 'in')\n",
    "        self.Wi.connect_all_to_all(weights=ann.Normal(0.0, 1.0))\n",
    "\n",
    "        # Recurrent weights\n",
    "        self.Wrec = ann.Projection(self.reservoir, self.reservoir, 'exc')\n",
    "        self.Wrec.connect_all_to_all(weights=ann.Normal(0., 1/np.sqrt(N)))\n",
    "\n",
    "        # Monitor\n",
    "        self.monitor = ann.Monitor(self.reservoir, 'r')\n",
    "\n",
    "        ann.compile()\n",
    "\n",
    "    def trial(self, g:float, duration:int=5000, amplitude:float=1.0):\n",
    "        \"\"\"\n",
    "        Runs a single trial for a given spectral radius.\n",
    "        \n",
    "        Args:\n",
    "            g: scaling factor.\n",
    "            duration: duration of the trial.\n",
    "            amplitude: amplitude of the impulse.\n",
    "        \"\"\"\n",
    "\n",
    "        # Reset and set spectral radius\n",
    "        self.inp.r = 0.0\n",
    "        self.reservoir.x = 0.0\n",
    "        self.reservoir.r = 0.0\n",
    "        self.reservoir.g = g\n",
    "        \n",
    "        # 100 ms of reset\n",
    "        ann.simulate(100.)\n",
    "        \n",
    "        # 100 ms of stimulation\n",
    "        self.inp.r = amplitude\n",
    "        ann.simulate(100.0)\n",
    "        \n",
    "        # Relax for the rest of the duration\n",
    "        self.inp.r = 0.0\n",
    "        ann.simulate(duration - 200.)\n",
    "        \n",
    "        # Return the firing rates r\n",
    "        data = self.monitor.get('r')    \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ESN(N=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** Run the network for multiple values of $g$ for 5 seconds, with an impulse of amplitude 1.0. Plot the firing rate of a handful of neuron (e.g. 5) and observe the influence of $g$ on the dynamics. When do complex dynamics appear?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q:** For different values of $g$, run two trials of the same network: one where the amplitude of the impulse is 1.0, the other where it is very slightly different (e.g. 1.00001). Plot the difference between the two runs. When does chaos appear? Do not hesitate to simulate for longer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use the reservoir as a spatiotemporal basis for supervised learning. We first need to define a target signal $t$ that will be used to train the weights of the readout population. We can use for example an impulse after 4 seconds as a target, but feel free to use whatever you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = np.zeros(5000)\n",
    "target[4000:4500] = 1.0\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(target)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of implementing a readout neuron and a linear regression / delta learning rule, we are going to make use of the `scikit-learn`'s linear regression implementation. \n",
    "\n",
    "If you have an input array `X` and a target array `t` (the first dimension of both arrays being samples), you can simply type:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X, t)\n",
    "```\n",
    "\n",
    "Ridge regression (<https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html>) is another popular option.\n",
    "\n",
    "You can then predict value for any other input array `X`:\n",
    "\n",
    "```python\n",
    "y = reg.predict(X)\n",
    "```\n",
    "\n",
    "**Q:** Train the linear regression algorithm on the activity of the reservoir as input. Samples are the firing rates of the reservoir at each time step (i.e. 5000 samples of dimension `N=500`). Test it on the same array and visualize the prediction. Can we linearly predict the target signal using an ESN? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Q:** Test the learned regression on the activity of the reservoir, but using an input impulse of slightly different amplitude (e.g. 1.00001). Vary $g$. Does it still work? Conclude on the stability and usability of ESN reservoirs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d24234067c217f49dc985cbc60012ce72928059d528f330ba9cb23ce737906d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
